{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54b037a7",
   "metadata": {},
   "source": [
    "# Text Preprocessing ‚Äì More Examples (Jupyter Notebook)\n",
    "\n",
    "This notebook contains multiple real-world text preprocessing examples that can be run cell by cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d40b34a",
   "metadata": {},
   "source": [
    "## Install & Download Requirements (Run Once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cc65b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b63e3b9",
   "metadata": {},
   "source": [
    "## Download NLTK Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491f8939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0dc71e",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b81a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0174dea4",
   "metadata": {},
   "source": [
    "## Example 1: Social Media Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c511a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"OMG!!! I love this phone üòçüòç #Amazing #WorthIt\"\n",
    "text = text.lower()\n",
    "text = re.sub(r\"#\\w+\", \"\", text)\n",
    "text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "tokens = word_tokenize(text)\n",
    "[w for w in tokens if w not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cf7795",
   "metadata": {},
   "source": [
    "## Example 2: Email Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1597efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Dear User, Please contact us at support@example.com ASAP!!!\"\n",
    "text = text.lower()\n",
    "text = re.sub(r\"\\S+@\\S+\", \"\", text)\n",
    "text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d2f026",
   "metadata": {},
   "source": [
    "## Example 3: Stopword Removal Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec473f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This movie is not good\"\n",
    "tokens = word_tokenize(text.lower())\n",
    "tokens, [w for w in tokens if w not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6aab259",
   "metadata": {},
   "source": [
    "## Example 4: Stemming vs Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0e072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['running', 'flies', 'better', 'studies']\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "[stemmer.stem(w) for w in words], [lemmatizer.lemmatize(w) for w in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072c959a",
   "metadata": {},
   "source": [
    "## Example 5: URL & Number Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b320258",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"India won the match by 6 wickets. Read more at https://news.com\"\n",
    "text = text.lower()\n",
    "text = re.sub(r\"http\\S+\", \"\", text)\n",
    "text = re.sub(r\"\\d+\", \"\", text)\n",
    "text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113c9751",
   "metadata": {},
   "source": [
    "## Example 6: Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb5c9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"NLP is powerful. It is used in AI. Many companies rely on it.\"\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c42c51a",
   "metadata": {},
   "source": [
    "## Example 7: Complete Reusable Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a1f4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
    "    text = re.sub(r\"\\S+@\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [w for w in tokens if w not in stopwords.words('english')]\n",
    "    return tokens\n",
    "\n",
    "preprocess_text(\"Contact me at test@mail.com!!! NLP is AWESOME üòç\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
